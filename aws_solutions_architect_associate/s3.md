# Simple Storage Service (S3)

- Object based (from 0 bytes to 5TB)
- Unlimited storage
- Files are stored in Bucket
- Bucket's name must be unique (two people can't have the same name)
- When you upload an object to S3, it should return a 200/HTTP response
- Objects are just files, on S3 they refer as Key which is the name of the file.
- Value is the data of the Key(file)
- Version ID (when you use versioning)
- Objects can include metadata
- Sub-resources: ACL and Torrent.
- Bucket name styles:
  - **https://your-bucket-name.s3-aws-region.amazonaws.com**
  - **https://s3-aws-region.amazonaws.com/your-bucket-name**
- **Uploading with multi-part upload:**
  - Delivers more network throughput
  - You can pause and resume objects
  - Recovers quickly from network issues
  - You can begin an upload before you know the final object size

# Data consistency on S3

- Read after Write for PUT of new objects: Once you upload the file you can read it straight away
- Consistency for overwrite PUTS/DELETE (delay in propagation): If you update/delete a file, is not guaranteed you will read the latest version of the file since it takes take to propagate those changes.

# Availability and Durability

- AWS guarantees 99.9% availability
- 99.999999999% (11 nines) durability for S3.

# S3 Features

- Tier Storage
- Lifecycle management
- Versioning
- Encryption (at rest)
- MFA to delete objects
- Secure your data with **ACLs** and **Bucket Policies**

# S3 Tiers (Storage Classes)

- S3 Standard: (99.99% availability and 11x9 durability), Stored redundantly across multi devices in several facilities. Designed to survive the loss of 2 AZ concurrently.
- S3 IA (Infrequent Access): For data that is accessed less frequently and cheaper than S3 standard. You get charged a small fee for data retrieval.
- S3 One Zone IA (Reduced Redundacy Storage): If you want a low cost solution for infrequent access data, stored only in 1 availability zone.
- S3 Intelligent Tiering (2018): Designed to optimised costs automatically using Machine Learning.

- S3 Glacier: Long term retention data and very low cost. Retrieval times are minutes or hours.
- S3 Glacier deep archive: lowest tier but retrieval time at least 12h.

Comparisson chart here `https://aws.amazon.com/s3/storage-classes/`

# How billing works in S3

```
Storage + Requests (number of requests) + Storage Tier + Data Transfer Pricing + Transfer Acceleration + Cross region replication Pricing
```

- Cross region replication is S3 bucket replication from one region to another (HA).
- S3 Transfer Acceleration: Makes the process of uploading files to S3 Faster using CloudFront's edge locations (network optimisations). The files get uploaded first to the edge location and then is replicated to the source.


# S3 Security and Encryption

- By default new bucket have `private` acl.
- Bucket policies operate at Bucket level and ACLs operate at an object level.
- Traffic between client and S3 is encrypted through SSL/TLS (in transit).
- Encryption at rest:
  - at server side (AWS):
    - SSE-S3 (Server Side Encryption). S3 manages the keys for encryption/decryption.
      - Encryption uses AES-256
      - Free to use
      - Each object is encrypted with a unique data key
      - Master key is periodically rotated automatically
      - No key management required
    - SSE-KMS (Server Side encryption KMS). AWS KMS manages the keys.
      - Keys are managed by AWS KMS
      - You control the keys
      - You choose which key the object is encrypted by
      - AES-256
      - `Data key` is encrypted by `master key`
      - You can audit all the API calls with CloudTrail.
      - There is a cost associated with using KMS.
    - SSE-C (Server side encryption with customer provided keys). Client (us) manages the key.
      - if you loose the key, you loose the object.
  - Encryption at rest - Client side encryption
    - You do encryption/encryption of objects.
    - Data is encrypted before sending to S3
    - Client SDK is limited to use `Java`, `Ruby`, `.NET`.

# S3 Cross Region Replication

- Deleting an object from source bucket will not be replicated (delete marker)
- Deleting latest versions will not be replicated either
- Only new objects are replicated (current objects need to be manually sync with destination bucket)
- To have Cross Region replication you need to enable "Versioning" in both buckets
- Regions have to be different (you can't replicate to another bucket in same region)

# S3 Transfer Acceleration

- Files get uploaded to a edge location (CloudFront) then replicated to source
- You get a unique endpoint to upload your objects such as `bucketname.s3-accelerate.amazonaws.com`
- You can test how fast Transfer Acceleration works with this tool  `https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html`
-

# Tips

- S3 is object based
- Files size is minimum 0 bytes to 5TB
- S3 is unlimited
- Files are stored in Buckets.
- S3 is a universal namespace (names are unique)
- Not suitable to install an OS on it (can you?)
- Sucessfully upload objects return 200/HTTP
- Objects can be protected from deletion using MFA
- Read after write for new objects (GET after a PUT could return stale data)
- Eventual consistency for updating objects (take time to propagate)
- Know S3 Storage Tiers (S3 standard, S3 IA, S3 One zone IA, S3 Intelligent Tiering, S3 Glacier, S3 Glacier deep archive)
- Read S3 FAQ - `https://aws.amazon.com/s3/faqs/?nc=sn&loc=7`
- Versioning on S3 cannot be disabled, only suspended.
- Requests rate for GET/HEAD 5,5000 x second. PUT/DELETE/UPDATE 3,500 x second. There are no limits to the number of prefixes in a bucket.  You can increase your read or write performance by parallelizing reads. For example, if you create 10 prefixes in an Amazon     S3 bucket to parallelize reads, you could scale your read performance to 55,000 read requests per second.
- You can restrict access to the S3 buckets by VPC Endpoint by using the aws:sourceVpce policy.